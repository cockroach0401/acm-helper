from __future__ import annotations

import httpx

from ..models.settings import AIProvider, AISettings


class AIClient:
    async def generate_solution(self, prompt: str, ai_settings: AISettings) -> str:
        return await self._generate(prompt, ai_settings)

    async def generate_report(self, prompt: str, ai_settings: AISettings) -> str:
        return await self._generate(prompt, ai_settings)

    async def generate_text(self, prompt: str, ai_settings: AISettings) -> str:
        return await self._generate(prompt, ai_settings)

    async def test_connection(self, ai_settings: AISettings) -> str:
        if ai_settings.provider == AIProvider.mock:
            return "mock provider available"

        probe_prompt = "Reply with exactly: ok"
        result = await self._generate(probe_prompt, ai_settings)
        return result[:200]

    async def _generate(self, prompt: str, ai_settings: AISettings) -> str:
        if ai_settings.provider == AIProvider.mock:
            return self._mock_response(prompt)
        if ai_settings.provider == AIProvider.openai_compatible:
            return await self._generate_via_openai_compatible(prompt, ai_settings)
        if ai_settings.provider == AIProvider.anthropic:
            return await self._generate_via_anthropic(prompt, ai_settings)
        raise RuntimeError(f"Unsupported provider: {ai_settings.provider}")

    async def _generate_via_openai_compatible(self, prompt: str, ai_settings: AISettings) -> str:
        if not ai_settings.api_base or not ai_settings.api_key:
            raise RuntimeError("AI api_base/api_key is not configured")

        url = self._resolve_openai_compatible_url(ai_settings.api_base)
        headers = {
            "Authorization": f"Bearer {ai_settings.api_key}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": ai_settings.model,
            "messages": [
                {"role": "system", "content": "You are an ACM solution assistant."},
                {"role": "user", "content": prompt},
            ],
            "temperature": ai_settings.temperature,
        }

        async with httpx.AsyncClient(timeout=ai_settings.timeout_seconds) as client:
            resp = await client.post(url, headers=headers, json=payload)
            resp.raise_for_status()
            data = resp.json()

        choices = data.get("choices", [])
        if not choices:
            raise RuntimeError("No choices returned from model provider")
        content = choices[0].get("message", {}).get("content", "")
        if not content:
            raise RuntimeError("Empty content returned from model provider")
        return content

    def _resolve_openai_compatible_url(self, api_base: str) -> str:
        base = api_base.strip().rstrip("/")
        if base.endswith("/v1/chat/completions"):
            return base
        if base.endswith("/chat/completions"):
            return base
        if base.endswith("/v1"):
            return base + "/chat/completions"
        return base + "/v1/chat/completions"

    async def _generate_via_anthropic(self, prompt: str, ai_settings: AISettings) -> str:
        if not ai_settings.api_base or not ai_settings.api_key:
            raise RuntimeError("AI api_base/api_key is not configured")

        url = ai_settings.api_base.rstrip("/") + "/v1/messages"
        headers = {
            "x-api-key": ai_settings.api_key,
            "anthropic-version": "2023-06-01",
            "Content-Type": "application/json",
        }
        payload = {
            "model": ai_settings.model,
            "max_tokens": 4096,
            "temperature": ai_settings.temperature,
            "messages": [{"role": "user", "content": prompt}],
        }

        async with httpx.AsyncClient(timeout=ai_settings.timeout_seconds) as client:
            resp = await client.post(url, headers=headers, json=payload)
            resp.raise_for_status()
            data = resp.json()

        content_blocks = data.get("content", [])
        text_parts: list[str] = []
        for block in content_blocks:
            if isinstance(block, dict) and block.get("type") == "text":
                text_parts.append(block.get("text", ""))

        content = "\n".join([part for part in text_parts if part]).strip()
        if not content:
            raise RuntimeError("Empty content returned from anthropic provider")
        return content

    def _mock_response(self, prompt: str) -> str:
        return "\n".join(
            [
                "# Mock AI Output",
                "",
                "This is a mock response used for local testing.",
                "",
                "## Preview",
                "- Output is generated by provider=mock",
                "- Replace with real provider settings for actual model output",
                "",
                "## Prompt Snippet",
                prompt[:500],
            ]
        )
